{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qml7Iv9sKwYG"
   },
   "source": [
    "# MIC Workshop 4: Recurrent Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNrL3aTpywZr"
   },
   "source": [
    "## Background\n",
    "Hope you're enjoying the first Deep Learning workshop so far! For these workshops, we'll typically use Google Colab, an online coding environment. This is so that we don't have to worry about installing all of the libraries on everyone's different computers. \n",
    "\n",
    "_____\n",
    "You're now working in a Notebook. Notebooks have **cells**, each of which can be run by hitting Shift+Enter. Try it on the cell below!\n",
    "\n",
    "_You will see the output of the particular cell right below it_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIU7z14RW_Nu"
   },
   "outputs": [],
   "source": [
    "print(\"Notebooks are so much fun!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfUb8YzkFQRz"
   },
   "source": [
    "In general, notebooks are a very suitable tool for machine learning/data science. We would also recommend trying [Jupyter Notebook](https://jupyter.org/install) if you haven't already\n",
    "\n",
    "_For later workshops, we might opt out for a more involved environment like Docker in case we want to do anything fancier_\n",
    "____\n",
    "## Installing PyTorch\n",
    "Don't worry too much about the contents of this cell. It basically just installs the right packages for you to run PyTorch code\n",
    "\n",
    "If this cell is causing problems for you (like `tcmalloc`,  make sure you click \"connect to Hosted runtime\" from the dropdown menu in the top right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "BsvMU7Q7KwzP",
    "outputId": "61b2b8c4-d93b-4c31-f31e-d2a8ac920817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 91.1MB 31.0MB/s \n",
      "\u001b[31mfastai 1.0.49 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mfastai 1.0.49 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25hCollecting unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 8.3MB/s \n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.0.23\n",
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 4.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.6)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.8.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-1.6\n"
     ]
    }
   ],
   "source": [
    "# Installing pytorch, don't worry about the code in this cell. \n",
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = 'cpu' #cuda_output[0] if exists('/dev/nvidia0')\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "!pip install unidecode\n",
    "!pip install tensorboardX\n",
    "\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsD1YE9g76O2"
   },
   "source": [
    "##Imports\n",
    "\n",
    "The imports for the following exercise are the following :\n",
    "\n",
    "**torch.nn** :  Allows for creation of neural network class\n",
    "\n",
    "**torch.autograd** : torch.autograd provides classes and functions implementing automatic differentiation\n",
    "\n",
    "**tensorboardX** : PyTorch package for Tensorboard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOGCa5JDK17n"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from IPython import display\n",
    "import tqdm\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4kame7P215c"
   },
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WvU9zelr7ivL"
   },
   "source": [
    "#(Optional Exercise)\n",
    "\n",
    "###Use PyTorch to implement cell description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6x4ITg_Fv7zY"
   },
   "source": [
    "###Elman Cell Computation\n",
    "An Elman RNN cell with tanh non-linearity.\n",
    "\n",
    "$$h_t=\\tanh(W_h x_t+U_h h_{t-1}+b_h)$$\n",
    "$$y_t=\\tanh(W_y h_t+b_y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L065AM7VUfSa"
   },
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        #TODO: Implement initializations\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        #TODO: Implement forward pass\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zK3wy8XmLM1d"
   },
   "source": [
    "# Dataset\n",
    "This dataset is a subset of works by William Shakespeare, this cell block downloads the data, reads and pre-processes and displays an example.\n",
    "\n",
    "\n",
    "You don't need to worry about the format too much now. But in general, getting the data in the necessary format is usually a key (albeit mundane) part of the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "52KWKp--LRVH",
    "outputId": "44a4cbb3-bbf0-4ae3-cc90-7d22aa832c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import string\n",
    "import random\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "def DownloadFile(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "  \n",
    "target_url = \"https://raw.githubusercontent.com/cos495/code/master/shakespeare.txt\"\n",
    "data = DownloadFile(target_url)\n",
    "print(data[10:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbXyGCo52dmD"
   },
   "source": [
    "##Pre-processing\n",
    "\n",
    "We take in the downloaded data and create training sets, which are encoded in the form of torch tensors for feeding into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Jl_FxV3-ZxX"
   },
   "outputs": [],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        try:\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        except:\n",
    "            continue\n",
    "    return tensor  \n",
    "\n",
    "def random_training_set(chunk_len, batch_size, file):\n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for bi in range(batch_size):\n",
    "        start_index = random.randint(0, len(file) - chunk_len)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = file[start_index:end_index]\n",
    "        inp[bi] = char_tensor(chunk[:-1])\n",
    "        target[bi] = char_tensor(chunk[1:])\n",
    "    inp = Variable(inp)\n",
    "    target = Variable(target)\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uw7E1yvHPbMD"
   },
   "source": [
    "#Model\n",
    "\n",
    "#RNN Cell Structure\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/759/1*UkI9za9zTR-HL8uM15Wmzw.png)\n",
    "\n",
    "\n",
    "The CharRNN (based on Andrej Karpathy's model described in [Unreasonable Effectiveness of RNNs by Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)) works character by character and attempts to predict the next character. This is then assimilated to produce the output.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In this program, we create the CharRNN class, in which we define the parameters of an encoder-decoder framework for text generation, you have the option of either using a vanilla RNN cell using nn.RNN or using a Long Short Term Memory unit (LSTM) using nn.LSTM.\n",
    "\n",
    "In this model, given a sequence of characters from this data (\"Shakespeare\") we train it to predict the next character in the sequence.\n",
    "\n",
    "You will be defining the parameters of the model, read through the documentation to get a feel of what the input to each line is is!\n",
    "\n",
    "\n",
    "\n",
    "[torch.nn.LSTM/RNN/Embedding](https://pytorch.org/docs/stable/nn.html)\n",
    "![alt text](https://chunml.github.io/ChunML.github.io/images/projects/sequence-to-sequence/repeated_vector.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9FA2RAisbzK"
   },
   "source": [
    "---\n",
    "First we will be taking in the data and create an encoding  by creating embeddings and this is will input to the RNN cell, which models the input and predicts the next character, this token is further decoded based on the embedding definition and displayed as the prediction.\n",
    "\n",
    "\n",
    "![alt text](https://camo.githubusercontent.com/00d11e704403d414e272c35bf89c9428e6d4d2ca/68747470733a2f2f692e696d6775722e636f6d2f4a4835387458592e706e67)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YM-RJy9gNcT3"
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model, n_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #https://pytorch.org/docs/stable/nn.html\n",
    "        \n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size,hidden_size,padding_idx = 0)  \n",
    "        self.rnn = nn.RNN(hidden_size,hidden_size,n_layers)\n",
    "        if model==\"lstm\":\n",
    "          self.rnn = nn.LSTM(hidden_size,hidden_size,n_layers)\n",
    "          \n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjolCWdP1fkS"
   },
   "source": [
    "#Training\n",
    "\n",
    "Now that you have defined the forward pass of the neural network it is time to define the parameters for training.\n",
    "\n",
    "**Hidden Size** - This is the number of hidden units present in the RNN cell.\n",
    "\n",
    "**Learning Rate** - Learning rate is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the loss gradient.\n",
    "\n",
    "**Model** : RNN or LSTM (LSTM takes longer to train)\n",
    "\n",
    "**n_layers** - Number of RNN Layers, the recommended number is 1 or 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KB9xsWiEQhkU"
   },
   "source": [
    "###Iinitialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDV_0GRbLtXw"
   },
   "outputs": [],
   "source": [
    "\n",
    "hidden_size = 500\n",
    "learning_rate = 0.001\n",
    "model = \"RNN\"\n",
    "n_layers = 1\n",
    "\n",
    "decoder = CharRNN(\n",
    "    n_characters,\n",
    "    hidden_size,\n",
    "    n_characters,\n",
    "    model,\n",
    "    n_layers=n_layers,\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if use_cuda:\n",
    "    decoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilkYK2mE0HbQ"
   },
   "source": [
    "**chunk_len** - Size of the random chunck of data used in every training pass\n",
    "\n",
    "**n_epochs** - Number of epochs for which the training will run.\n",
    "\n",
    "**print_every** - Frequency with which you want to print predictions\n",
    "\n",
    "**batch_size** - Number of training examples per batch (Number of chunks per batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRdaN2-FRndV"
   },
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "chunk_len = 20\n",
    "print_every = 10\n",
    "batch_size = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3bFZTUxwBlm"
   },
   "source": [
    "#Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KPmkvGJPkNt"
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden(batch_size)\n",
    "    if use_cuda:\n",
    "        hidden = hidden.cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[:,c], hidden)\n",
    "        loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / chunk_len, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8M-FSO-TTLF"
   },
   "source": [
    "# Generate Text\n",
    "\n",
    "In this cell, we are declaring a starting character which serves as the token or seed the first input, which the RNN will use to start predicting the next character\n",
    "\n",
    "**predict_len** - Length of prediction expected\n",
    "\n",
    "**Temperature** - Temperature is a hyperparameter of LSTMs (and neural networks generally) used to control the randomness of predictions by scaling the logits before applying softmax. \n",
    "\n",
    "![alt text](https://docs.google.com/uc?id=13nBWDE7RXlnMmT2g_BJQ4brFO7YIuh1Q)\n",
    "\n",
    "**cuda** - Run generate on GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gh4cIaRDS23s"
   },
   "outputs": [],
   "source": [
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, cuda=False):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
    "    \n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[:,p], hidden)\n",
    "        \n",
    "    inp = prime_input[:,-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkimd5lvIH8p"
   },
   "source": [
    "#Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2193
    },
    "colab_type": "code",
    "id": "riXDDbny1-DF",
    "outputId": "34dbb489-6fdb-4403-8bae-8e8c8992089a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 200 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:01<00:38,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 1s (10 5%) 2.7424]\n",
      "loss:  2.742435264587402\n",
      "Whou dous bors\n",
      "Tor, kth mhouvec wihat, woud aait as hal hat fit an sond linleurgd y mand basy or hiith \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [00:03<00:36,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 3s (20 10%) 2.4619]\n",
      "loss:  2.461871528625488\n",
      "Whine ty shatu sll nechat sead tre it is orfor thand 'n.\n",
      "\n",
      "Sy to ghe the thir lis vouste kn sh yowe an  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [00:05<00:33,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 5s (30 15%) 2.3536]\n",
      "loss:  2.353593635559082\n",
      "Wher foorith an as gour sand yould to, areterthe sale seace,.\n",
      "\n",
      "PETRDUS:\n",
      "IUCENIA mytu worent thea th gh \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [00:07<00:30,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 7s (40 20%) 2.2903]\n",
      "loss:  2.290310287475586\n",
      "Wh wil that ou tile thed uneds:es you the'd of frein't; spard me ame jeman ea the wich sreqred the han \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [00:09<00:29,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 9s (50 25%) 2.1749]\n",
      "loss:  2.1749174118041994\n",
      "When don most de\n",
      "The harking sade, may he fand andere, hit the conesuno outhand Is.\n",
      "\n",
      "AUARI:\n",
      "\n",
      "Fole the  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [00:11<00:27,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 11s (60 30%) 2.1723]\n",
      "loss:  2.172323799133301\n",
      "Whained he puith and hame heeld cowe sere for:\n",
      "Tham spare in the\n",
      "Se toll mabe seawt to my you head buy \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [00:13<00:25,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 13s (70 35%) 2.1555]\n",
      "loss:  2.1555456161499023\n",
      "Who guine lo sell aon dot\n",
      "Whe dueat the thus no hour Syour that knot fore he wall broull wo sing, it y \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [00:15<00:23,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 15s (80 40%) 2.1153]\n",
      "loss:  2.1152873992919923\n",
      "Whauld the geather your his oot en heac?\n",
      "\n",
      "KING CARV:\n",
      "I the diviso in forter your he geacienien;\n",
      "Gy ben \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [00:17<00:21,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 17s (90 45%) 2.0483]\n",
      "loss:  2.048330307006836\n",
      "Whture'd the yon, ss to had stane the with am thour the man is to will but the rith eas for for the ca \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [00:19<00:20,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 19s (100 50%) 2.0655]\n",
      "loss:  2.0654836654663087\n",
      "Whe yout that, the dich for the have beang?\n",
      "\n",
      "Sircen onm, that mid,\n",
      "'ich os bo say you,\n",
      "The cawe; be ro \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [00:20<00:18,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 20s (110 55%) 2.0240]\n",
      "loss:  2.024038314819336\n",
      "Whis lored savertes conad my he lackaru, for dade dew, and here have wilt. and nourter.\n",
      "\n",
      "CABEURIO:\n",
      "My  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [00:22<00:15,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 22s (120 60%) 1.9800]\n",
      "loss:  1.9799598693847655\n",
      "Whe shaugh a treart ind nue here mustio.\n",
      "\n",
      "COLINGHLO:\n",
      "O are that I'll:\n",
      "HAMING EDWARD:\n",
      "Bet son, for mest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 130/200 [00:24<00:14,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 24s (130 65%) 1.9740]\n",
      "loss:  1.9739503860473633\n",
      "Wht with Lorn,\n",
      "That it and your dees.\n",
      "Sur be the poor bliess and againce pose and me the have is cold. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140/200 [00:26<00:12,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 26s (140 70%) 2.0223]\n",
      "loss:  2.0223390579223635\n",
      "Whoure\n",
      "Thy Carmonged my is the him the oo shoud frill all and should sponet shoor nes stather of fain  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 150/200 [00:28<00:09,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 28s (150 75%) 1.9149]\n",
      "loss:  1.9149349212646485\n",
      "What, yeake the feat be fall that the anien:\n",
      "Dich vith so refalie.\n",
      "\n",
      "CIPELO*:\n",
      "Ny lirst this lian dest t \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [00:30<00:08,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 30s (160 80%) 1.9787]\n",
      "loss:  1.9787225723266602\n",
      "Why me this dithinese fine to it it subert fighath is the stase and trusest her welveld to thy Serpton \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170/200 [00:32<00:06,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 32s (170 85%) 2.0125]\n",
      "loss:  2.012546730041504\n",
      "Wheth\n",
      "Where to seef gronque the blown lords though And which her you hake peake thes have dray: what w \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [00:34<00:03,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 34s (180 90%) 1.8622]\n",
      "loss:  1.8622039794921874\n",
      "Why, to the of mantie.\n",
      "\n",
      "LUCENTES:\n",
      "He with they grive slison prome to gros, theaigs now, thee hound by  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [00:36<00:02,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 36s (190 95%) 1.9022]\n",
      "loss:  1.9021902084350586\n",
      "When peen wating and broth tellence,\n",
      "Whall and net were, is nince Durnt sach all the gead thee hat bec \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:38<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 38s (200 100%) 1.9281]\n",
      "loss:  1.9280763626098634\n",
      "Wher may on not good you carposs me out be cead, here your then the lives\n",
      "Cropselt: that.\n",
      "\n",
      "LUCHIO:\n",
      "See \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loss_all = []\n",
    "writer = SummaryWriter()\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in tqdm.tqdm(range(1, n_epochs + 1)):\n",
    "    loss = train(*random_training_set(chunk_len, batch_size, data))[0]\n",
    "    loss_all.append(loss)\n",
    "    writer.add_scalar('Training Loss', loss, epoch)\n",
    "    #writer.add_histogram(\"hist\", (train(*random_training_set(chunk_len, batch_size, data))[1]).detach().numpy(), epoch)\n",
    "    if epoch % print_every == 0:\n",
    "      print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "      print('loss: ', loss)\n",
    "      print(generate(decoder, 'Wh', 100, cuda=use_cuda), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "CmkwHEew0oU8",
    "outputId": "9d6144eb-9436-426d-bc74-01a412d05323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f13adf1b0f0>]"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZALIYTFSZALIYTFSZALIYTF/X9bUJWT8WmR2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7snNirbPzaDk"
   },
   "source": [
    "\n",
    "### Let's try sampling with high temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0oCPS6kzRK4w",
    "outputId": "d8561f8b-dd58-4131-84f2-ec03fccdc25a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"art thy7@Js-YgH|Upt3$.Pb#>c{\\\\{k{:%]];O51+%QV\\n}DIYIL!)AFmwX$F_xhQ )WJ*H'%.[!TuxB\\x0c84p.>y\\\\rFG%^zfMUi^ 0gruvs>,\""
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(decoder, prime_str=\"art thy\", temperature= 100, cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1g9IOY-zmZ8"
   },
   "source": [
    "\n",
    "\n",
    "### Let's try sampling with low temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "77ijhzn9Tc1C",
    "outputId": "97d3e59b-92af-4d0f-a6a3-dc2139e96073"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My lady not now's welt the wise and he hath the deart me this you him streain un the streater so prient she\""
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(decoder, prime_str=\"My lady\", temperature= 0.6, cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2KRkbkm1MT_"
   },
   "source": [
    "#Feedback Survey\n",
    "Don't forget to fill out the feedback survey [here](https://goo.gl/rXV5EQ) for suggestions on how we can improve our future workshops!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I88wTPCJ1bls"
   },
   "source": [
    "##Citations\n",
    "\n",
    "Adapted from https://github.com/spro/char-rnn.pytorch\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of MIC Workshop 4 : Recurrent Neural Networks.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
